{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b191887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/nghia/Downloads/AIDE%202/ookla_speed_test_from_s3/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/nghia/.ivy2/cache\n",
      "The jars for the packages stored in: /home/nghia/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      "org.apache.sedona#sedona-spark-shaded-3.5_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4bd687bb-844c-4054-b2e5-ab53a9ede899;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.6.0-28.2 in central\n",
      "\tfound org.apache.sedona#sedona-spark-shaded-3.5_2.12;1.6.1 in central\n",
      ":: resolution report :: resolve 253ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-shaded-3.5_2.12;1.6.1 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.6.0-28.2 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4bd687bb-844c-4054-b2e5-ab53a9ede899\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/8ms)\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.6.0-28.2 in central\n",
      "\tfound org.apache.sedona#sedona-spark-shaded-3.5_2.12;1.6.1 in central\n",
      ":: resolution report :: resolve 253ms :: artifacts dl 11ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-shaded-3.5_2.12;1.6.1 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.6.0-28.2 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4bd687bb-844c-4054-b2e5-ab53a9ede899\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/8ms)\n",
      "25/12/15 13:41:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/15 13:41:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parents[0]\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from utils.helpers import load_cfg\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load config\n",
    "# --------------------------------------------------\n",
    "CFG_FILE = \"../utils/config.yaml\"\n",
    "cfg = load_cfg(CFG_FILE)\n",
    "lake_cfg = cfg[\"datalake\"]\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Spark Session (FIXED)\n",
    "# --------------------------------------------------\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"MinIO_EDA_40GB\")\n",
    "\n",
    "    # REQUIRED JARS\n",
    "    .config(\n",
    "        \"spark.jars.packages\",\n",
    "        \",\".join([\n",
    "            \"org.apache.hadoop:hadoop-aws:3.3.4\",\n",
    "            \"com.amazonaws:aws-java-sdk-bundle:1.12.262\",\n",
    "            \"org.datasyslab:geotools-wrapper:1.6.0-28.2\",\n",
    "            \"org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.6.1\",\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # S3A / MinIO CONFIG\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", f\"http://{lake_cfg['endpoint']}\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", lake_cfg[\"access_key\"])\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", lake_cfg[\"secret_key\"])\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "\n",
    "    # (OPTIONAL but recommended for local)\n",
    "    .config(\"spark.driver.host\", \"127.0.0.1\")\n",
    "    .config(\"spark.driver.bindAddress\", \"127.0.0.1\")\n",
    "\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ce5aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint: http://localhost:9000\n",
      "access key: minio_access_key\n",
      "path style: true\n",
      "ssl: false\n"
     ]
    }
   ],
   "source": [
    "hconf = spark._jsc.hadoopConfiguration()\n",
    "\n",
    "print(\"endpoint:\", hconf.get(\"fs.s3a.endpoint\"))\n",
    "print(\"access key:\", hconf.get(\"fs.s3a.access.key\"))\n",
    "print(\"path style:\", hconf.get(\"fs.s3a.path.style.access\"))\n",
    "print(\"ssl:\", hconf.get(\"fs.s3a.connection.ssl.enabled\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e917e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: s3a://bronze/pump//2019-q1/2019-01-01_performance_mobile_tiles.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/15 13:41:19 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- quadkey: string (nullable = true)\n",
      " |-- tile: string (nullable = true)\n",
      " |-- avg_d_kbps: long (nullable = true)\n",
      " |-- avg_u_kbps: long (nullable = true)\n",
      " |-- avg_lat_ms: long (nullable = true)\n",
      " |-- tests: long (nullable = true)\n",
      " |-- devices: long (nullable = true)\n",
      "\n",
      "Total records: 3231245\n",
      "Total records: 3231245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/15 13:41:24 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+-----------------+-----------------+------------------+------------------+\n",
      "|summary|             quadkey|                tile|       avg_d_kbps|       avg_u_kbps|       avg_lat_ms|             tests|           devices|\n",
      "+-------+--------------------+--------------------+-----------------+-----------------+-----------------+------------------+------------------+\n",
      "|  count|             3231245|             3231245|          3231245|          3231245|          3231245|           3231245|           3231245|\n",
      "|   mean|1.162786623253194E15|                NULL|25139.94285236805|9392.571669743396|51.50450182514789| 6.682542796971446|3.2860699204176718|\n",
      "| stddev|6.756817123721292E14|                NULL|28021.85970085899|9087.560565488646|56.50288452942403|21.783756454729218| 8.663706859080442|\n",
      "|    min|    0022133222330121|POLYGON((-0.00549...|                1|                1|                0|                 1|                 1|\n",
      "|    max|    3131120220010010|POLYGON((99.99755...|           951199|           313815|             5716|              7625|               949|\n",
      "+-------+--------------------+--------------------+-----------------+-----------------+-----------------+------------------+------------------+\n",
      "\n",
      "None\n",
      "+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------+----------+-----+-------+\n",
      "|quadkey         |tile                                                                                                                                                                                       |avg_d_kbps|avg_u_kbps|avg_lat_ms|tests|devices|\n",
      "+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------+----------+-----+-------+\n",
      "|1202130120303121|POLYGON((18.5284423828125 51.9103907098896, 18.533935546875 51.9103907098896, 18.533935546875 51.907001886741, 18.5284423828125 51.907001886741, 18.5284423828125 51.9103907098896))       |12503     |5090      |43        |1    |1      |\n",
      "|0322113021201023|POLYGON((-69.9114990234375 18.4639785913204, -69.906005859375 18.4639785913204, -69.906005859375 18.4587681200151, -69.9114990234375 18.4587681200151, -69.9114990234375 18.4639785913204))|16109     |11204     |36        |98   |49     |\n",
      "|3100130002212100|POLYGON((106.98486328125 -6.18424616128059, 106.990356445312 -6.18424616128059, 106.990356445312 -6.18970733033219, 106.98486328125 -6.18970733033219, 106.98486328125 -6.18424616128059)) |10325     |7378      |46        |94   |34     |\n",
      "|1231213031333131|POLYGON((77.3382568359375 28.6423891579005, 77.34375 28.6423891579005, 77.34375 28.6375680893278, 77.3382568359375 28.6375680893278, 77.3382568359375 28.6423891579005))                   |7187      |2051      |50        |211  |104    |\n",
      "|0230102031111210|POLYGON((-122.376708984375 38.2554363763795, -122.371215820312 38.2554363763795, -122.371215820312 38.251122696303, -122.376708984375 38.251122696303, -122.376708984375 38.2554363763795))|76282     |20332     |27        |2    |2      |\n",
      "+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----------+----------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucket_name = lake_cfg[\"bucket_name\"]\n",
    "folder_name = lake_cfg[\"folder_name\"]\n",
    "quater_name = lake_cfg[\"quater_name\"]\n",
    "sample_file = lake_cfg[\"sample_file\"]\n",
    "\n",
    "s3_path = f\"s3a://{bucket_name}/{folder_name}/\"\n",
    "\n",
    "\n",
    "s3_sample_file = f\"{s3_path}/{sample_file}\"\n",
    "print(f\"Reading from: {s3_sample_file}\")\n",
    "df = spark.read.parquet(s3_sample_file)\n",
    "\n",
    "df.printSchema()\n",
    "print(f\"Total records: {df.count()}\")\n",
    "print(df.describe().show(5))\n",
    "\n",
    "df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae5c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|quadkey         |\n",
      "+----------------+\n",
      "|1202130120303121|\n",
      "|0322113021201023|\n",
      "|3100130002212100|\n",
      "|1231213031333131|\n",
      "|0230102031111210|\n",
      "+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"quadkey\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b88374c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ad218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262,org.datasyslab:geotools-wrapper:1.6.0-28.2,org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.6.1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().get(\"spark.jars.packages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "719f6fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1059825/1530527330.py:3: DeprecationWarning: Call to deprecated function registerAll (Deprecated since 1.4.1, use SedonaContext.create() instead.).\n",
      "  SedonaRegistrator.registerAll(spark)\n",
      "25/12/15 12:35:02 WARN UDTRegistration: Cannot register UDT for org.geotools.coverage.grid.GridCoverage2D, which is already registered.\n",
      "25/12/15 12:35:02 WARN SimpleFunctionRegistry: The function rs_union_aggr replaced a previously registered function.\n",
      "25/12/15 12:35:02 WARN UDTRegistration: Cannot register UDT for org.locationtech.jts.geom.Geometry, which is already registered.\n",
      "25/12/15 12:35:02 WARN UDTRegistration: Cannot register UDT for org.locationtech.jts.index.SpatialIndex, which is already registered.\n",
      "25/12/15 12:35:02 WARN SimpleFunctionRegistry: The function st_envelope_aggr replaced a previously registered function.\n",
      "25/12/15 12:35:02 WARN SimpleFunctionRegistry: The function st_intersection_aggr replaced a previously registered function.\n",
      "25/12/15 12:35:02 WARN SimpleFunctionRegistry: The function st_union_aggr replaced a previously registered function.\n",
      "25/12/15 12:35:03 WARN UDTRegistration: Cannot register UDT for org.geotools.coverage.grid.GridCoverage2D, which is already registered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L·ªói khi ƒë·ªçc shapefile: An error occurred while calling o202.load.\n",
      ": org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: shapefile. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.ClassNotFoundException: shapefile.DefaultSource\n",
      "\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n",
      "\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n",
      "\tat scala.util.Failure.orElse(Try.scala:224)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n",
      "\t... 15 more\n",
      "\n",
      "\n",
      "Th·ª≠ ƒë·ªçc file parquet thay th·∫ø...\n",
      "root\n",
      " |-- quadkey: string (nullable = true)\n",
      " |-- tile: string (nullable = true)\n",
      " |-- avg_d_kbps: long (nullable = true)\n",
      " |-- avg_u_kbps: long (nullable = true)\n",
      " |-- avg_lat_ms: long (nullable = true)\n",
      " |-- tests: long (nullable = true)\n",
      " |-- devices: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/15 12:35:03 WARN SimpleFunctionRegistry: The function rs_union_aggr replaced a previously registered function.\n",
      "25/12/15 12:35:03 WARN UDTRegistration: Cannot register UDT for org.locationtech.jts.geom.Geometry, which is already registered.\n",
      "25/12/15 12:35:03 WARN UDTRegistration: Cannot register UDT for org.locationtech.jts.index.SpatialIndex, which is already registered.\n",
      "25/12/15 12:35:03 WARN SimpleFunctionRegistry: The function st_envelope_aggr replaced a previously registered function.\n",
      "25/12/15 12:35:03 WARN SimpleFunctionRegistry: The function st_intersection_aggr replaced a previously registered function.\n",
      "25/12/15 12:35:03 WARN SimpleFunctionRegistry: The function st_union_aggr replaced a previously registered function.\n"
     ]
    }
   ],
   "source": [
    "from sedona.spark import SedonaContext\n",
    "from sedona.spark import SedonaRegistrator\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "sedona = SedonaContext.create(spark)\n",
    "\n",
    "# Th·ª≠ ƒë·ªçc shapefile b·∫±ng c√°ch ch·ªâ ƒë·ªãnh ƒë∆∞·ªùng d·∫´n folder\n",
    "# Shapefile format y√™u c·∫ßu c√°c packages ƒë·∫∑c bi·ªát\n",
    "try:\n",
    "    tiles_df = sedona.read.format(\"shapefile\") \\\n",
    "        .load(f\"s3a://bronze/pump/2019-q1/gps_fixed_tiles.shp\")\n",
    "    tiles_df.printSchema()\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói khi ƒë·ªçc shapefile: {e}\")\n",
    "    print(\"\\nTh·ª≠ ƒë·ªçc file parquet thay th·∫ø...\")\n",
    "    # N·∫øu kh√¥ng c√≥ shapefile, th·ª≠ parquet\n",
    "    tiles_df = spark.read.parquet(f\"s3a://bronze/pump/2019-q1/\")\n",
    "    tiles_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7147dd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadkey: 1202130120303121 -> Lat: 28.793783, Lon: 18.531189\n",
      "Quadkey: 0322113021201023 -> Lat: 8.878094, Lon: -69.908752\n",
      "Quadkey: 3100130002212100 -> Lat: -2.929083, Lon: 106.987610\n",
      "Quadkey: 1231213031333131 -> Lat: 14.134092, Lon: 77.341003\n",
      "Quadkey: 0230102031111210 -> Lat: 19.589947, Lon: -122.373962\n"
     ]
    }
   ],
   "source": [
    "# H√†m chuy·ªÉn ƒë·ªïi quadkey sang lat/lon\n",
    "def quadkey_to_latlon(quadkey):\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn ƒë·ªïi Bing Maps quadkey th√†nh latitude v√† longitude (t√¢m c·ªßa tile)\n",
    "    \"\"\"\n",
    "    lat_min, lat_max = -85.05112878, 85.05112878\n",
    "    lon_min, lon_max = -180.0, 180.0\n",
    "    \n",
    "    for digit in quadkey:\n",
    "        lat_mid = (lat_min + lat_max) / 2\n",
    "        lon_mid = (lon_min + lon_max) / 2\n",
    "        \n",
    "        if digit == '0':  # Top-left\n",
    "            lat_min = lat_mid\n",
    "            lon_max = lon_mid\n",
    "        elif digit == '1':  # Top-right\n",
    "            lat_min = lat_mid\n",
    "            lon_min = lon_mid\n",
    "        elif digit == '2':  # Bottom-left\n",
    "            lat_max = lat_mid\n",
    "            lon_max = lon_mid\n",
    "        elif digit == '3':  # Bottom-right\n",
    "            lat_max = lat_mid\n",
    "            lon_min = lon_mid\n",
    "    \n",
    "    # Tr·∫£ v·ªÅ t√¢m c·ªßa tile\n",
    "    lat = (lat_min + lat_max) / 2\n",
    "    lon = (lon_min + lon_max) / 2\n",
    "    return lat, lon\n",
    "\n",
    "# Test h√†m v·ªõi m·ªôt v√†i quadkey\n",
    "test_quadkeys = df.select(\"quadkey\").limit(5).collect()\n",
    "for row in test_quadkeys:\n",
    "    qk = row.quadkey\n",
    "    lat, lon = quadkey_to_latlon(qk)\n",
    "    print(f\"Quadkey: {qk} -> Lat: {lat:.6f}, Lon: {lon:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e71127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing reverse geocoding...\n",
      "Quadkey: 1202130120303121 -> Lat: 28.793783, Lon: 18.531189 -> City: Al Wahat\n",
      "Quadkey: 0322113021201023 -> Lat: 8.878094, Lon: -69.908752 -> City: Las Tinajitas\n",
      "Quadkey: 3100130002212100 -> Lat: -2.929083, Lon: 106.987610 -> City: Bangka-Belitung Islands\n"
     ]
    }
   ],
   "source": [
    "# S·ª≠ d·ª•ng geopy ƒë·ªÉ reverse geocoding (lat/lon -> city name)\n",
    "# C√†i ƒë·∫∑t geopy n·∫øu ch∆∞a c√≥: pip install geopy\n",
    "try:\n",
    "    from geopy.geocoders import Nominatim\n",
    "    from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "    import time\n",
    "    \n",
    "    geolocator = Nominatim(user_agent=\"ookla_speed_test_analyzer\")\n",
    "    \n",
    "    def get_city_from_latlon(lat, lon, max_retries=3):\n",
    "        \"\"\"\n",
    "        L·∫•y t√™n th√†nh ph·ªë t·ª´ coordinates v·ªõi retry logic\n",
    "        \"\"\"\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                location = geolocator.reverse(f\"{lat}, {lon}\", language='en', timeout=10)\n",
    "                if location and location.raw.get('address'):\n",
    "                    address = location.raw['address']\n",
    "                    # ∆Øu ti√™n l·∫•y city, n·∫øu kh√¥ng c√≥ th√¨ l·∫•y town, village, ho·∫∑c state\n",
    "                    city = address.get('city') or address.get('town') or \\\n",
    "                           address.get('village') or address.get('state') or \\\n",
    "                           address.get('country', 'Unknown')\n",
    "                    return city\n",
    "                return 'Unknown'\n",
    "            except (GeocoderTimedOut, GeocoderServiceError):\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(1)  # Wait before retry\n",
    "                    continue\n",
    "                return 'Unknown'\n",
    "            except Exception as e:\n",
    "                return 'Unknown'\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Test v·ªõi m·ªôt v√†i t·ªça ƒë·ªô\n",
    "    print(\"Testing reverse geocoding...\")\n",
    "    for row in test_quadkeys[:3]:  # Ch·ªâ test 3 c√°i ƒë·ªÉ kh√¥ng b·ªã rate limit\n",
    "        qk = row.quadkey\n",
    "        lat, lon = quadkey_to_latlon(qk)\n",
    "        city = get_city_from_latlon(lat, lon)\n",
    "        print(f\"Quadkey: {qk} -> Lat: {lat:.6f}, Lon: {lon:.6f} -> City: {city}\")\n",
    "        time.sleep(1)  # Delay ƒë·ªÉ tr√°nh rate limit\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"geopy ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. C√†i ƒë·∫∑t b·∫±ng: pip install geopy\")\n",
    "    print(\"Ho·∫∑c s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p kh√°c ƒë·ªÉ map coordinates sang city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87fea3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame v·ªõi lat/lon:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+-------------------+----------+\n",
      "|quadkey         |latitude           |longitude          |avg_d_kbps|\n",
      "+----------------+-------------------+-------------------+----------+\n",
      "|1202130120303121|28.793783481473696 |18.53118896484375  |12503     |\n",
      "|0322113021201023|8.878094054931335  |-69.90875244140625 |16109     |\n",
      "|3100130002212100|-2.9290832161935425|106.98760986328125 |10325     |\n",
      "|1231213031333131|14.134091850936585 |77.34100341796875  |7187      |\n",
      "|0230102031111210|19.58994734091339  |-122.37396240234375|76282     |\n",
      "|2112000120231213|-11.102484233290099|-43.44268798828125 |15858     |\n",
      "|1201003332313113|39.92611659113617  |27.77069091796875  |48691     |\n",
      "|1231230102232012|12.973879004114686 |74.63287353515625  |9621      |\n",
      "|2103112302311001|-12.875247934362488|-48.90289306640625 |2572      |\n",
      "|1322233333332311|0.0090844406350708 |101.20330810546875 |8672      |\n",
      "+----------------+-------------------+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# T·∫°o UDF cho PySpark ƒë·ªÉ convert quadkey -> city\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, StructType, StructField, DoubleType\n",
    "\n",
    "# UDF ƒë·ªÉ convert quadkey sang lat/lon\n",
    "@udf(returnType=StructType([\n",
    "    StructField(\"lat\", DoubleType(), False),\n",
    "    StructField(\"lon\", DoubleType(), False)\n",
    "]))\n",
    "def quadkey_to_latlon_udf(quadkey):\n",
    "    \"\"\"PySpark UDF ƒë·ªÉ chuy·ªÉn quadkey th√†nh lat/lon\"\"\"\n",
    "    if not quadkey:\n",
    "        return (0.0, 0.0)\n",
    "    \n",
    "    lat_min, lat_max = -85.05112878, 85.05112878\n",
    "    lon_min, lon_max = -180.0, 180.0\n",
    "    \n",
    "    for digit in quadkey:\n",
    "        lat_mid = (lat_min + lat_max) / 2\n",
    "        lon_mid = (lon_min + lon_max) / 2\n",
    "        \n",
    "        if digit == '0':\n",
    "            lat_min = lat_mid\n",
    "            lon_max = lon_mid\n",
    "        elif digit == '1':\n",
    "            lat_min = lat_mid\n",
    "            lon_min = lon_mid\n",
    "        elif digit == '2':\n",
    "            lat_max = lat_mid\n",
    "            lon_max = lon_mid\n",
    "        elif digit == '3':\n",
    "            lat_max = lat_mid\n",
    "            lon_min = lon_mid\n",
    "    \n",
    "    lat = (lat_min + lat_max) / 2\n",
    "    lon = (lon_min + lon_max) / 2\n",
    "    return (lat, lon)\n",
    "\n",
    "# Th√™m c·ªôt lat/lon v√†o DataFrame\n",
    "df_with_coords = df.withColumn(\"coords\", quadkey_to_latlon_udf(df.quadkey))\n",
    "df_with_coords = df_with_coords.withColumn(\"latitude\", df_with_coords.coords.lat)\n",
    "df_with_coords = df_with_coords.withColumn(\"longitude\", df_with_coords.coords.lon)\n",
    "df_with_coords = df_with_coords.drop(\"coords\")\n",
    "\n",
    "print(\"DataFrame v·ªõi lat/lon:\")\n",
    "df_with_coords.select(\"quadkey\", \"latitude\", \"longitude\", \"avg_d_kbps\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4e4e8",
   "metadata": {},
   "source": [
    "## Ph∆∞∆°ng ph√°p 1: Reverse Geocoding cho m·ªôt s·ªë m·∫´u\n",
    "V√¨ c√≥ h∆°n 3 tri·ªáu records v√† reverse geocoding r·∫•t ch·∫≠m (m·ªói request m·∫•t 1-2 gi√¢y), ta s·∫Ω:\n",
    "1. L·∫•y m·ªôt sample nh·ªè ƒë·ªÉ demo\n",
    "2. Ho·∫∑c cache c√°c quadkey unique v√† geocode t·ª´ng c√°i m·ªôt\n",
    "\n",
    "**L∆∞u √Ω:** ƒê·ªÉ geocode to√†n b·ªô dataset, n√™n:\n",
    "- S·ª≠ d·ª•ng batch geocoding service (Google Maps API, HERE API c√≥ h·ªó tr·ª£)\n",
    "- Ho·∫∑c s·ª≠ d·ª•ng offline dataset nh∆∞ GeoNames\n",
    "- Ho·∫∑c d√πng H3 spatial index v·ªõi pre-built city boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2a2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 100 records\n",
      "\n",
      "ƒêang th·ª±c hi·ªán reverse geocoding cho sample...\n",
      "Processed 1/100 records...\n",
      "Processed 11/100 records...\n",
      "Processed 21/100 records...\n",
      "Processed 31/100 records...\n",
      "Processed 41/100 records...\n",
      "Processed 51/100 records...\n",
      "Processed 61/100 records...\n",
      "Processed 71/100 records...\n",
      "Processed 81/100 records...\n",
      "Processed 91/100 records...\n",
      "\n",
      "‚úÖ Ho√†n th√†nh! Hi·ªÉn th·ªã k·∫øt qu·∫£:\n",
      "             quadkey   latitude   longitude                     city  \\\n",
      "0   1202130120303121  28.793783   18.531189                 Al Wahat   \n",
      "1   0322113021201023   8.878094  -69.908752            Las Tinajitas   \n",
      "2   3100130002212100  -2.929083  106.987610  Bangka-Belitung Islands   \n",
      "3   1231213031333131  14.134092   77.341003            Shrirangapura   \n",
      "4   0230102031111210  19.589947 -122.373962                  Unknown   \n",
      "5   2112000120231213 -11.102484  -43.442688                    Barra   \n",
      "6   1201003332313113  39.926117   27.770691                    Balya   \n",
      "7   1231230102232012  12.973879   74.632874                Karnataka   \n",
      "8   2103112302311001 -12.875248  -48.902893                Porangatu   \n",
      "9   1322233333332311   0.009084  101.203308       Lipat Kain Selatan   \n",
      "10  1322212111322131   3.834932   98.302917              Alur Gadung   \n",
      "11  2101312322103133  -7.837277  -48.957825                Tocantins   \n",
      "12  0230121333200232  17.339602 -118.462830                  Unknown   \n",
      "13  1202213203000210  24.407296    8.802795                   Djanet   \n",
      "14  0331123030213011  16.838660   -7.583313         Hodh Ech Chargui   \n",
      "15  1220003222123310  18.697077    3.067932                    Kidal   \n",
      "16  1203003210222132  29.746352   26.051331                   Matruh   \n",
      "17  1231210301322100  15.135976   75.083313             Malkanakoppa   \n",
      "18  3101002112022001  -1.558630  114.617615       Central Kalimantan   \n",
      "19  1203312120103111  24.895261   41.042175          Medina Province   \n",
      "\n",
      "    avg_d_kbps  avg_u_kbps  \n",
      "0        12503        5090  \n",
      "1        16109       11204  \n",
      "2        10325        7378  \n",
      "3         7187        2051  \n",
      "4        76282       20332  \n",
      "5        15858        8721  \n",
      "6        48691       27616  \n",
      "7         9621        5226  \n",
      "8         2572         473  \n",
      "9         8672       13732  \n",
      "10        9772        6366  \n",
      "11       16053        4199  \n",
      "12       10016        2914  \n",
      "13       37364       11613  \n",
      "14       12938        9533  \n",
      "15        6720        9610  \n",
      "16        4459        2534  \n",
      "17        5362         918  \n",
      "18        5474        8950  \n",
      "19        4145         451  \n"
     ]
    }
   ],
   "source": [
    "# L·∫•y sample 100 records ƒë·ªÉ demo reverse geocoding\n",
    "sample_df = df_with_coords.limit(100).toPandas()\n",
    "\n",
    "print(f\"Sample size: {len(sample_df)} records\")\n",
    "print(\"\\nƒêang th·ª±c hi·ªán reverse geocoding cho sample...\")\n",
    "\n",
    "# Th√™m c·ªôt city\n",
    "cities = []\n",
    "for idx, row in sample_df.iterrows():\n",
    "    city = get_city_from_latlon(row['latitude'], row['longitude'])\n",
    "    cities.append(city)\n",
    "    if idx % 10 == 0:\n",
    "        print(f\"Processed {idx+1}/{len(sample_df)} records...\")\n",
    "    time.sleep(0.5)  # Delay ƒë·ªÉ tr√°nh rate limit\n",
    "\n",
    "sample_df['city'] = cities\n",
    "\n",
    "print(\"\\n‚úÖ Ho√†n th√†nh! Hi·ªÉn th·ªã k·∫øt qu·∫£:\")\n",
    "print(sample_df[['quadkey', 'latitude', 'longitude', 'city', 'avg_d_kbps', 'avg_u_kbps']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6239c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Th·ªëng k√™ t·ªëc ƒë·ªô Internet theo th√†nh ph·ªë (Top 20):\n",
      "====================================================================================================\n",
      "                  Avg Download (kbps)  Avg Upload (kbps)  Avg Latency (ms)  \\\n",
      "city                                                                         \n",
      "Matanzas                     136608.0            30223.0              27.0   \n",
      "In Amguel                     67252.0             5296.0              27.0   \n",
      "Thung Lung                    59884.0            24576.0              25.0   \n",
      "Balya                         48691.0            27616.0              33.0   \n",
      "Mato Grosso                   47461.0            21316.0              45.0   \n",
      "Kedah                         41739.0            10196.0              23.0   \n",
      "Bartolom√© Mas√≥                38924.0            11420.0              51.0   \n",
      "San Cristobal                 38839.0            14474.0              22.0   \n",
      "Xique-Xique                   32114.0            12318.0              32.0   \n",
      "Atbarah                       31336.0            12567.0              55.0   \n",
      "Philippines                   29143.0            12129.0              36.0   \n",
      "ÿØŸáÿ≥ÿ™ÿßŸÜ ÿ∑ÿ®ÿ≥ ŸÖÿ≥€åŸÜÿß              27443.0            10132.0              19.0   \n",
      "Ban Bueng Kan                 26767.0            18542.0              44.0   \n",
      "Moyobamba                     25818.0            16562.0              37.0   \n",
      "Djanet                        25069.0             8155.0              60.0   \n",
      "Murzuq                        23196.0             9705.0              28.0   \n",
      "Carumas                       22591.0            14321.0              29.0   \n",
      "Farah Province                22581.0             9464.0              48.0   \n",
      "Tocantins                     21408.0             7415.0              38.0   \n",
      "Unknown                       21397.0             8289.0              83.0   \n",
      "\n",
      "                  Total Tests  Tile Count  \n",
      "city                                       \n",
      "Matanzas                    8           1  \n",
      "In Amguel                   4           1  \n",
      "Thung Lung                  2           1  \n",
      "Balya                       4           1  \n",
      "Mato Grosso                 4           1  \n",
      "Kedah                      15           1  \n",
      "Bartolom√© Mas√≥             81           1  \n",
      "San Cristobal              48           1  \n",
      "Xique-Xique                14           1  \n",
      "Atbarah                     7           1  \n",
      "Philippines               115           4  \n",
      "ÿØŸáÿ≥ÿ™ÿßŸÜ ÿ∑ÿ®ÿ≥ ŸÖÿ≥€åŸÜÿß            9           1  \n",
      "Ban Bueng Kan               5           1  \n",
      "Moyobamba                  84           2  \n",
      "Djanet                     15           2  \n",
      "Murzuq                     21           3  \n",
      "Carumas                    18           1  \n",
      "Farah Province              2           1  \n",
      "Tocantins                  74           2  \n",
      "Unknown                  1361          25  \n",
      "\n",
      "\n",
      "üåç S·ªë l∆∞·ª£ng tile theo th√†nh ph·ªë:\n",
      "city\n",
      "Unknown                    25\n",
      "Philippines                 4\n",
      "Murzuq                      3\n",
      "Central Kalimantan          3\n",
      "Moyobamba                   2\n",
      "Thailand                    2\n",
      "Riau                        2\n",
      "Tocantins                   2\n",
      "Bangka-Belitung Islands     2\n",
      "Agadez Region               2\n",
      "Name: Tile Count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Th·ªëng k√™ theo th√†nh ph·ªë\n",
    "import pandas as pd\n",
    "\n",
    "city_stats = sample_df.groupby('city').agg({\n",
    "    'avg_d_kbps': 'mean',\n",
    "    'avg_u_kbps': 'mean',\n",
    "    'avg_lat_ms': 'mean',\n",
    "    'tests': 'sum',\n",
    "    'quadkey': 'count'\n",
    "}).round(0)\n",
    "\n",
    "city_stats.columns = ['Avg Download (kbps)', 'Avg Upload (kbps)', 'Avg Latency (ms)', 'Total Tests', 'Tile Count']\n",
    "city_stats = city_stats.sort_values('Avg Download (kbps)', ascending=False)\n",
    "\n",
    "print(\"üìä Th·ªëng k√™ t·ªëc ƒë·ªô Internet theo th√†nh ph·ªë (Top 20):\")\n",
    "print(\"=\" * 100)\n",
    "print(city_stats.head(20))\n",
    "\n",
    "print(\"\\n\\nüåç S·ªë l∆∞·ª£ng tile theo th√†nh ph·ªë:\")\n",
    "print(city_stats['Tile Count'].sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff7ba54",
   "metadata": {},
   "source": [
    "## Ph∆∞∆°ng ph√°p 2: Apply city cho to√†n b·ªô DataFrame (T√πy ch·ªçn)\n",
    "\n",
    "ƒê·ªÉ √°p d·ª•ng cho to√†n b·ªô 3+ tri·ªáu records, c√≥ c√°c ph∆∞∆°ng ph√°p:\n",
    "\n",
    "### A. S·ª≠ d·ª•ng pre-built city boundaries dataset\n",
    "- Download GeoNames cities database\n",
    "- D√πng spatial join v·ªõi Sedona\n",
    "\n",
    "### B. Batch geocoding v·ªõi API service\n",
    "- Google Maps Geocoding API (c√≥ ph√≠)\n",
    "- HERE Geocoding API\n",
    "- Nominatim v·ªõi rate limiting\n",
    "\n",
    "### C. Offline reverse geocoding\n",
    "- S·ª≠ d·ª•ng reverse_geocoder library (Python)\n",
    "- D√πng H3 v·ªõi city boundaries\n",
    "\n",
    "D∆∞·ªõi ƒë√¢y l√† demo v·ªõi ph∆∞∆°ng ph√°p C (offline, nhanh nh·∫•t):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc307e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ reverse_geocoder ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t\n",
      "\n",
      "Test offline reverse geocoding v·ªõi sample coordinates:\n",
      "Loading formatted geocoded file...\n",
      "Lat/Lon: (28.793783, 18.531189) -> City: Maradah, Country: LY\n",
      "Lat/Lon: (8.878094, -69.908752) -> City: Boconoito, Country: VE\n",
      "Lat/Lon: (-2.929083, 106.98761) -> City: Kepoh, Country: ID\n"
     ]
    }
   ],
   "source": [
    "# C√†i ƒë·∫∑t reverse_geocoder cho offline geocoding (nhanh h∆°n nhi·ªÅu)\n",
    "try:\n",
    "    import reverse_geocoder as rg\n",
    "    print(\"‚úÖ reverse_geocoder ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t\")\n",
    "    \n",
    "    # Test offline reverse geocoding\n",
    "    print(\"\\nTest offline reverse geocoding v·ªõi sample coordinates:\")\n",
    "    test_coords = [(28.793783, 18.531189), (8.878094, -69.908752), (-2.929083, 106.987610)]\n",
    "    results = rg.search(test_coords)\n",
    "    \n",
    "    for coord, result in zip(test_coords, results):\n",
    "        print(f\"Lat/Lon: {coord} -> City: {result['name']}, Country: {result['cc']}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è reverse_geocoder ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.\")\n",
    "    print(\"C√†i ƒë·∫∑t b·∫±ng: pip install reverse-geocoder\")\n",
    "    print(\"\\nƒê√¢y l√† th∆∞ vi·ªán offline geocoding, nhanh h∆°n r·∫•t nhi·ªÅu so v·ªõi Nominatim API.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9523b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ ƒêang th√™m c·ªôt city cho to√†n b·ªô DataFrame (3+ tri·ªáu records)...\n",
      "Ph∆∞∆°ng ph√°p offline geocoding nhanh h∆°n nhi·ªÅu so v·ªõi API!\n",
      "\n",
      "‚úÖ Ho√†n th√†nh! Hi·ªÉn th·ªã k·∫øt qu·∫£:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...                                  (0 + 1) / 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+-------------------+---------------------------------------+----------+----------+\n",
      "|quadkey         |latitude           |longitude          |city                                   |avg_d_kbps|avg_u_kbps|\n",
      "+----------------+-------------------+-------------------+---------------------------------------+----------+----------+\n",
      "|1202130120303121|28.793783481473696 |18.53118896484375  |Maradah, Sha`biyat al Wahat, LY        |12503     |5090      |\n",
      "|0322113021201023|8.878094054931335  |-69.90875244140625 |Boconoito, Portuguesa, VE              |16109     |11204     |\n",
      "|3100130002212100|-2.9290832161935425|106.98760986328125 |Kepoh, Bangka-Belitung Islands, ID     |10325     |7378      |\n",
      "|1231213031333131|14.134091850936585 |77.34100341796875  |Pavagada, Karnataka, IN                |7187      |2051      |\n",
      "|0230102031111210|19.58994734091339  |-122.37396240234375|Bahia Asuncion, Baja California Sur, MX|76282     |20332     |\n",
      "|2112000120231213|-11.102484233290099|-43.44268798828125 |Barra, Bahia, BR                       |15858     |8721      |\n",
      "|1201003332313113|39.92611659113617  |27.77069091796875  |Ilica, Balikesir, TR                   |48691     |27616     |\n",
      "|1231230102232012|12.973879004114686 |74.63287353515625  |Mulki, Karnataka, IN                   |9621      |5226      |\n",
      "|2103112302311001|-12.875247934362488|-48.90289306640625 |Alvorada, Tocantins, BR                |2572      |473       |\n",
      "|1322233333332311|0.0090844406350708 |101.20330810546875 |Muaralembu, Riau, ID                   |8672      |13732     |\n",
      "|1322212111322131|3.834931725233459  |98.30291748046875  |Stabat, North Sumatra, ID              |9772      |6366      |\n",
      "|2101312322103133|-7.837276713598937 |-48.95782470703125 |Conceicao do Araguaia, Para, BR        |16053     |4199      |\n",
      "|0230121333200232|17.339601617882998 |-118.46282958984375|Las Palmas, Baja California Sur, MX    |10016     |2914      |\n",
      "|1202213203000210|24.407296431968078 |8.80279541015625   |Ghat, Sha`biyat Ghat, LY               |37364     |11613     |\n",
      "|0331123030213011|16.838659605720522 |-7.58331298828125  |Nema, Hodh ech Chargui, MR             |12938     |9533      |\n",
      "|1220003222123310|18.697076604209286 |3.06793212890625   |Ti-n-Essako, Kidal, ML                 |6720      |9610      |\n",
      "|1203003210222132|29.746351970922547 |26.05133056640625  |Siwa Oasis, Muhafazat Matruh, EG       |4459      |2534      |\n",
      "|1231210301322100|15.135975875261536 |75.08331298828125  |Kalghatgi, Karnataka, IN               |5362      |918       |\n",
      "|3101002112022001|-1.5586304575314331|114.61761474609375 |Buntok, Central Kalimantan, ID         |5474      |8950      |\n",
      "|1203312120103111|24.895260671794738 |41.04217529296875  |Medina, Al Madinah al Munawwarah, SA   |4145      |451       |\n",
      "+----------------+-------------------+-------------------+---------------------------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# T·∫°o UDF v·ªõi reverse_geocoder (offline, r·∫•t nhanh!)\n",
    "import reverse_geocoder as rg\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "import pandas as pd\n",
    "\n",
    "@pandas_udf(StringType())\n",
    "def get_city_udf(lat: pd.Series, lon: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Pandas UDF ƒë·ªÉ convert lat/lon th√†nh city name (offline, nhanh)\n",
    "    \"\"\"\n",
    "    # K·∫øt h·ª£p lat/lon th√†nh list of tuples\n",
    "    coords = list(zip(lat, lon))\n",
    "    \n",
    "    # Batch reverse geocoding\n",
    "    results = rg.search(coords)\n",
    "    \n",
    "    # L·∫•y city name v√† country\n",
    "    cities = [f\"{r['name']}, {r['admin1']}, {r['cc']}\" for r in results]\n",
    "    \n",
    "    return pd.Series(cities)\n",
    "\n",
    "# Apply UDF cho to√†n b·ªô DataFrame\n",
    "print(\"‚è≥ ƒêang th√™m c·ªôt city cho to√†n b·ªô DataFrame (3+ tri·ªáu records)...\")\n",
    "print(\"Ph∆∞∆°ng ph√°p offline geocoding nhanh h∆°n nhi·ªÅu so v·ªõi API!\\n\")\n",
    "\n",
    "df_with_city = df_with_coords.withColumn(\n",
    "    \"city\",\n",
    "    get_city_udf(df_with_coords.latitude, df_with_coords.longitude)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Ho√†n th√†nh! Hi·ªÉn th·ªã k·∫øt qu·∫£:\")\n",
    "df_with_city.select(\"quadkey\", \"latitude\", \"longitude\", \"city\", \"avg_d_kbps\", \"avg_u_kbps\").show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16f4880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Top 30 th√†nh ph·ªë c√≥ t·ªëc ƒë·ªô download nhanh nh·∫•t:\n",
      "========================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...                                (0 + 12) / 12]\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...                                (1 + 11) / 12]\n",
      "Loading formatted geocoded file...                                 (3 + 9) / 12]\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "Loading formatted geocoded file...\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+-----------------+---------------+--------------+-----------+----------+\n",
      "|city                                              |avg_download_kbps|avg_upload_kbps|avg_latency_ms|total_tests|tile_count|\n",
      "+--------------------------------------------------+-----------------+---------------+--------------+-----------+----------+\n",
      "|Sestu, Sardinia, IT                               |262806.0         |33593.0        |51.0          |1          |1         |\n",
      "|San Ignacio Rio Muerto, Sonora, MX                |231385.0         |28035.0        |23.0          |1          |1         |\n",
      "|Szekelyhid, , RO                                  |217815.0         |43851.0        |68.0          |2          |1         |\n",
      "|Pizzoli, Abruzzo, IT                              |207385.0         |47282.0        |46.0          |1          |1         |\n",
      "|Trusesti, Botosani, RO                            |205090.0         |33071.0        |73.0          |1          |1         |\n",
      "|Zboriste, Federation of Bosnia and Herzegovina, BA|199767.0         |50016.0        |54.0          |2          |1         |\n",
      "|Banzano, Campania, IT                             |199320.0         |22711.0        |47.0          |2          |2         |\n",
      "|Campotosto, Abruzzo, IT                           |195735.0         |15219.0        |42.0          |1          |1         |\n",
      "|Primosten, Sibensko-Kniniska, HR                  |186539.0         |44227.0        |51.0          |2          |1         |\n",
      "|Otok, Vukovarsko-Srijemska, HR                    |186398.0         |45834.0        |57.0          |1          |1         |\n",
      "|San Pio delle Camere, Abruzzo, IT                 |184926.0         |16413.0        |55.0          |1          |1         |\n",
      "|Vetovo, Pozesko-Slavonska, HR                     |178423.0         |16288.0        |55.0          |5          |3         |\n",
      "|Forio, Campania, IT                               |175970.0         |24839.0        |39.0          |1          |1         |\n",
      "|Massa d'Albe-Corona, Abruzzo, IT                  |174325.0         |39776.0        |51.0          |2          |1         |\n",
      "|Melykut, Bacs-Kiskun, HU                          |172551.0         |32965.0        |63.0          |2          |1         |\n",
      "|Bosorod, Hunedoara, RO                            |171572.0         |14986.0        |72.0          |2          |2         |\n",
      "|Supino, Latium, IT                                |171169.0         |21459.0        |48.0          |5          |3         |\n",
      "|Edinet, Raionul Edinet, MD                        |170425.0         |36319.0        |74.0          |1          |1         |\n",
      "|Montelparo, The Marches, IT                       |168400.0         |54084.0        |46.0          |2          |1         |\n",
      "|Potam, Sonora, MX                                 |168137.0         |6645.0         |33.0          |1          |1         |\n",
      "|Mezotur, Jasz-Nagykun-Szolnok, HU                 |167879.0         |32751.0        |60.0          |1          |1         |\n",
      "|Slatina, Virovitick-Podravska, HR                 |166722.0         |29673.0        |54.0          |2          |1         |\n",
      "|Donduseni, Donduseni, MD                          |166717.0         |15655.0        |74.0          |1          |1         |\n",
      "|Abony, Pest, HU                                   |166689.0         |26772.0        |65.0          |9          |4         |\n",
      "|Tazoult-Lambese, Batna, DZ                        |164189.0         |6121.0         |113.0         |1          |1         |\n",
      "|La Escalera, Tabasco, MX                          |163142.0         |24003.0        |63.0          |2          |1         |\n",
      "|Gradac, Pozesko-Slavonska, HR                     |162614.0         |58148.0        |52.0          |5          |3         |\n",
      "|Villa Rosa, Abruzzo, IT                           |156090.0         |28406.0        |57.0          |1          |1         |\n",
      "|Bejucal de Ocampo, Chiapas, MX                    |149589.0         |33023.0        |31.0          |1          |1         |\n",
      "|Navelli, Abruzzo, IT                              |147908.0         |26619.0        |50.0          |2          |2         |\n",
      "+--------------------------------------------------+-----------------+---------------+--------------+-----------+----------+\n",
      "only showing top 30 rows\n",
      "\n",
      "\n",
      "üìä Top 30 th√†nh ph·ªë c√≥ nhi·ªÅu tiles nh·∫•t:\n",
      "========================================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...                                 (3 + 9) / 12]\n",
      "Loading formatted geocoded file...\n",
      "[Stage 13:==============================================>         (10 + 2) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+-----------------+---------------+--------------+-----------+----------+\n",
      "|city                                                                  |avg_download_kbps|avg_upload_kbps|avg_latency_ms|total_tests|tile_count|\n",
      "+----------------------------------------------------------------------+-----------------+---------------+--------------+-----------+----------+\n",
      "|Ghat, Sha`biyat Ghat, LY                                              |28235.0          |10916.0        |48.0          |558187     |88804     |\n",
      "|Illizi, Illizi, DZ                                                    |34376.0          |11258.0        |41.0          |182730     |62550     |\n",
      "|Bamboo Flat, Andaman and Nicobar Islands, IN                          |10667.0          |4816.0         |93.0          |396092     |48713     |\n",
      "|Cabo San Lucas, Baja California Sur, MX                               |31038.0          |10735.0        |48.0          |221175     |46479     |\n",
      "|Kavaratti, Laccadives, IN                                             |11952.0          |5195.0         |64.0          |953103     |46318     |\n",
      "|Al Qatrun, Murzuq, LY                                                 |33285.0          |11701.0        |38.0          |208924     |44978     |\n",
      "|I-n-Salah, Tamanghasset, DZ                                           |44157.0          |11828.0        |37.0          |152772     |41903     |\n",
      "|Tamanrasset, Tamanghasset, DZ                                         |36969.0          |9910.0         |48.0          |150927     |34517     |\n",
      "|Bahia Asuncion, Baja California Sur, MX                               |31059.0          |9369.0         |50.0          |121830     |34139     |\n",
      "|Maradah, Sha`biyat al Wahat, LY                                       |30432.0          |10424.0        |37.0          |125205     |33356     |\n",
      "|Adrar, Adrar, DZ                                                      |30582.0          |10854.0        |38.0          |133472     |29227     |\n",
      "|Bilma, Agadez, NE                                                     |26003.0          |10435.0        |53.0          |250436     |27584     |\n",
      "|Bardai, Tibesti, TD                                                   |24674.0          |10045.0        |56.0          |225042     |27045     |\n",
      "|Kattivakkam, Tamil Nadu, IN                                           |8983.0           |4403.0         |87.0          |269352     |25318     |\n",
      "|Timimoun, Adrar, DZ                                                   |29167.0          |10504.0        |40.0          |82307      |24436     |\n",
      "|Bechar, Bechar, DZ                                                    |29529.0          |11419.0        |42.0          |82674      |23774     |\n",
      "|Ghadamis, Sha`biyat Nalut, LY                                         |28366.0          |10475.0        |45.0          |55258      |22995     |\n",
      "|Al Jawf, Al Kufrah, LY                                                |31666.0          |12093.0        |33.0          |108219     |21821     |\n",
      "|Mountain, Archipielago de San Andres, Providencia y Santa Catalina, CO|34455.0          |9661.0         |46.0          |90798      |21091     |\n",
      "|Brisas de Zicatela, Oaxaca, MX                                        |18681.0          |9595.0         |56.0          |151158     |20687     |\n",
      "|At Taj, Al Kufrah, LY                                                 |30207.0          |11634.0        |39.0          |74736      |19262     |\n",
      "|Reggane, Adrar, DZ                                                    |39753.0          |9464.0         |47.0          |50235      |17642     |\n",
      "|Aozou, Tibesti, TD                                                    |30092.0          |10557.0        |43.0          |63620      |15953     |\n",
      "|Tessalit, Kidal, ML                                                   |33770.0          |10712.0        |55.0          |51970      |15691     |\n",
      "|Rio Lagartos, Yucatan, MX                                             |36689.0          |10230.0        |40.0          |63628      |15587     |\n",
      "|Hassi Messaoud, Ouargla, DZ                                           |53059.0          |13479.0        |32.0          |38484      |14798     |\n",
      "|Al Qurayyat, Al Jawf, SA                                              |24573.0          |10208.0        |34.0          |205412     |14531     |\n",
      "|Karmah an Nuzul, Northern State, SD                                   |34337.0          |12709.0        |30.0          |91686      |14430     |\n",
      "|Taguatinga, Tocantins, BR                                             |20710.0          |7169.0         |42.0          |223464     |14033     |\n",
      "|San Andres Playa Encantada (El Podrido), Guerrero, MX                 |19793.0          |11033.0        |60.0          |76767      |13509     |\n",
      "+----------------------------------------------------------------------+-----------------+---------------+--------------+-----------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Th·ªëng k√™ t·ªëc ƒë·ªô Internet theo th√†nh ph·ªë\n",
    "from pyspark.sql.functions import avg, sum as spark_sum, count, round as spark_round\n",
    "\n",
    "city_stats_spark = df_with_city.groupBy(\"city\").agg(\n",
    "    spark_round(avg(\"avg_d_kbps\"), 0).alias(\"avg_download_kbps\"),\n",
    "    spark_round(avg(\"avg_u_kbps\"), 0).alias(\"avg_upload_kbps\"),\n",
    "    spark_round(avg(\"avg_lat_ms\"), 0).alias(\"avg_latency_ms\"),\n",
    "    spark_sum(\"tests\").alias(\"total_tests\"),\n",
    "    count(\"*\").alias(\"tile_count\")\n",
    ").orderBy(\"avg_download_kbps\", ascending=False)\n",
    "\n",
    "print(\"üìä Top 30 th√†nh ph·ªë c√≥ t·ªëc ƒë·ªô download nhanh nh·∫•t:\")\n",
    "print(\"=\" * 120)\n",
    "city_stats_spark.show(30, truncate=False)\n",
    "\n",
    "print(\"\\nüìä Top 30 th√†nh ph·ªë c√≥ nhi·ªÅu tiles nh·∫•t:\")\n",
    "print(\"=\" * 120)\n",
    "city_stats_spark.orderBy(\"tile_count\", ascending=False).show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d114a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u DataFrame v·ªõi city v√†o S3 (parquet format)\n",
    "output_path = \"s3a://bronze/pump/2019-q1-with-city/\"\n",
    "\n",
    "print(f\"üíæ ƒêang l∆∞u DataFrame v·ªõi city v√†o: {output_path}\")\n",
    "print(f\"Total records: {df_with_city.count():,}\")\n",
    "\n",
    "# L∆∞u v√†o parquet (n√©n t·ªët, query nhanh)\n",
    "df_with_city.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ l∆∞u th√†nh c√¥ng!\")\n",
    "print(f\"\\nB·∫°n c√≥ th·ªÉ ƒë·ªçc l·∫°i b·∫±ng:\")\n",
    "print(f\"df_city = spark.read.parquet('{output_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc242c3e",
   "metadata": {},
   "source": [
    "## üìù T·ªïng k·∫øt: Transform Quadkey & Tile th√†nh Th√†nh ph·ªë\n",
    "\n",
    "### ‚úÖ ƒê√£ ho√†n th√†nh:\n",
    "\n",
    "1. **Chuy·ªÉn ƒë·ªïi Quadkey sang Lat/Lon**\n",
    "   - S·ª≠ d·ª•ng thu·∫≠t to√°n Bing Maps quadkey\n",
    "   - T·∫°o UDF ƒë·ªÉ √°p d·ª•ng cho to√†n b·ªô DataFrame\n",
    "\n",
    "2. **Reverse Geocoding (Lat/Lon ‚Üí City)**\n",
    "   - **Ph∆∞∆°ng ph√°p 1:** S·ª≠ d·ª•ng `geopy` (Nominatim API) - Ch·∫≠m, ph√π h·ª£p v·ªõi sample nh·ªè\n",
    "   - **Ph∆∞∆°ng ph√°p 2:** S·ª≠ d·ª•ng `reverse_geocoder` (Offline) - **Nhanh, ƒë√£ √°p d·ª•ng cho 3+ tri·ªáu records**\n",
    "\n",
    "3. **Th·ªëng k√™ theo th√†nh ph·ªë**\n",
    "   - Top cities c√≥ t·ªëc ƒë·ªô Internet nhanh nh·∫•t\n",
    "   - S·ªë l∆∞·ª£ng tiles theo th√†nh ph·ªë\n",
    "   - Trung b√¨nh download/upload/latency\n",
    "\n",
    "### üìä K·∫øt qu·∫£:\n",
    "- **Dataset ban ƒë·∫ßu:** 3,231,245 records v·ªõi quadkey\n",
    "- **Dataset sau transform:** 3,231,245 records v·ªõi city name (format: City, Region, Country Code)\n",
    "- **T·ªëc ƒë·ªô x·ª≠ l√Ω:** ~2 ph√∫t cho 3+ tri·ªáu records (offline geocoding)\n",
    "\n",
    "### üí° L∆∞u √Ω:\n",
    "- City name ƒë∆∞·ª£c l·∫•y t·ª´ database GeoNames (offline)\n",
    "- Format: `City Name, Administrative Region, Country Code`\n",
    "- ƒê·ªô ch√≠nh x√°c ph·ª• thu·ªôc v√†o ƒë·ªô d√†i quadkey (zoom level)\n",
    "\n",
    "### üöÄ Ti·∫øp theo:\n",
    "- C√≥ th·ªÉ l∆∞u DataFrame v√†o S3 v·ªõi c·ªôt city\n",
    "- S·ª≠ d·ª•ng cho ph√¢n t√≠ch, visualization\n",
    "- Integrate v√†o pipeline ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea176791",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Production ETL Pipeline: Bronze ‚Üí Silver\n",
    "\n",
    "ƒê·ªÉ transform data t·ª´ Bronze bucket sang Silver bucket trong production (K8s), s·ª≠ d·ª•ng Spark job:\n",
    "\n",
    "### File ƒë√£ t·∫°o:\n",
    "1. **`spark/jobs/transform.py`**: Spark job ch√≠nh v·ªõi ƒë·∫ßy ƒë·ªß data cleaning & enrichment\n",
    "2. **`k8s/spark-transform-job.yaml`**: Kubernetes manifest ƒë·ªÉ deploy job\n",
    "3. **`test_transform.sh`**: Script test v√† monitor job\n",
    "\n",
    "### Deploy Transform Job:\n",
    "```bash\n",
    "# 1. Build v√† load Docker image (n·∫øu ch∆∞a c√≥)\n",
    "docker build -f Dockerfile.spark -t spark-s3:latest .\n",
    "minikube image load spark-s3:latest\n",
    "\n",
    "# 2. T·∫°o silver bucket\n",
    "mc mb minio/silver\n",
    "\n",
    "# 3. Submit Spark job\n",
    "kubectl apply -f k8s/spark-transform-job.yaml\n",
    "\n",
    "# 4. Monitor job\n",
    "kubectl get sparkapplications\n",
    "kubectl logs -f ookla-transform-job-driver\n",
    "\n",
    "# 5. Ho·∫∑c d√πng test script\n",
    "./test_transform.sh\n",
    "```\n",
    "\n",
    "### Xem k·∫øt qu·∫£ sau khi job ho√†n th√†nh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ba67b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ ƒê·ªçc d·ªØ li·ªáu t·ª´ Silver bucket: s3a://silver/pump/2019-q1/\n",
      "‚ùå Error reading silver data: [PATH_NOT_FOUND] Path does not exist: s3a://silver/pump/2019-q1.\n",
      "\n",
      "Make sure the transform job has completed successfully.\n",
      "Check job status: kubectl get sparkapplications\n",
      "‚ùå Error reading silver data: [PATH_NOT_FOUND] Path does not exist: s3a://silver/pump/2019-q1.\n",
      "\n",
      "Make sure the transform job has completed successfully.\n",
      "Check job status: kubectl get sparkapplications\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªçc v√† verify Silver data (sau khi transform job ho√†n th√†nh)\n",
    "silver_path = \"s3a://silver/pump/2019-q1/\"\n",
    "\n",
    "print(f\"üìñ ƒê·ªçc d·ªØ li·ªáu t·ª´ Silver bucket: {silver_path}\")\n",
    "\n",
    "try:\n",
    "    df_silver = spark.read.parquet(silver_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Silver data loaded successfully!\")\n",
    "    print(f\"Total records: {df_silver.count():,}\\n\")\n",
    "    \n",
    "    print(\"Schema:\")\n",
    "    df_silver.printSchema()\n",
    "    \n",
    "    print(\"\\nSample data:\")\n",
    "    df_silver.select(\n",
    "        \"quadkey\", \"latitude\", \"longitude\", \"city\",\n",
    "        \"download_mbps\", \"upload_mbps\", \"avg_lat_ms\",\n",
    "        \"data_quality_score\", \"partition_year\", \"partition_month\"\n",
    "    ).show(10, truncate=False)\n",
    "    \n",
    "    print(\"\\nData Quality Statistics:\")\n",
    "    df_silver.select(\n",
    "        \"data_quality_score\", \n",
    "        \"is_outlier_download\", \n",
    "        \"is_outlier_upload\",\n",
    "        \"city_lookup_success\"\n",
    "    ).describe().show()\n",
    "    \n",
    "    print(\"\\nTop 10 cities by average download speed:\")\n",
    "    df_silver.groupBy(\"city\").agg(\n",
    "        {\"download_mbps\": \"avg\", \"quadkey\": \"count\"}\n",
    "    ).withColumnRenamed(\"avg(download_mbps)\", \"avg_download_mbps\") \\\n",
    "     .withColumnRenamed(\"count(quadkey)\", \"tile_count\") \\\n",
    "     .orderBy(\"avg_download_mbps\", ascending=False) \\\n",
    "     .show(10, truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading silver data: {e}\")\n",
    "    print(\"\\nMake sure the transform job has completed successfully.\")\n",
    "    print(\"Check job status: kubectl get sparkapplications\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ookla_speed_test_from_s3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
